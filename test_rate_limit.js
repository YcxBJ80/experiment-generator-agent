import OpenAI from 'openai';
import dotenv from 'dotenv';
dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: 'https://openrouter.ai/api/v1',
});

async function testRateLimit() {
  console.log('ğŸ§ª æµ‹è¯•é€Ÿç‡é™åˆ¶é—®é¢˜...\n');
  
  for (let i = 1; i <= 3; i++) {
    console.log(`ğŸ“¡ ç¬¬${i}æ¬¡APIè°ƒç”¨...`);
    
    const start = Date.now();
    try {
      const completion = await openai.chat.completions.create({
        model: 'meta-llama/llama-3.2-3b-instruct:free',
        messages: [
          {
            role: 'user',
            content: 'è¯·è¯´"ä½ å¥½"'
          }
        ],
        max_tokens: 50
      });
      
      const duration = Date.now() - start;
      const response = completion.choices[0]?.message?.content || '';
      
      console.log(`âœ… æˆåŠŸ! è€—æ—¶: ${duration}ms`);
      console.log(`ğŸ“ å“åº”: "${response}"`);
      console.log(`ğŸ“Š å“åº”é•¿åº¦: ${response.length}\n`);
      
    } catch (error) {
      const duration = Date.now() - start;
      console.log(`âŒ å¤±è´¥! è€—æ—¶: ${duration}ms`);
      console.log(`ğŸ” é”™è¯¯ç±»å‹: ${error.constructor.name}`);
      console.log(`ğŸ’¬ é”™è¯¯æ¶ˆæ¯: ${error.message}`);
      
      if (error.status) {
        console.log(`ğŸŒ HTTPçŠ¶æ€: ${error.status}`);
      }
      
      if (error.error?.message) {
        console.log(`ğŸ“‹ è¯¦ç»†é”™è¯¯: ${error.error.message}`);
      }
      
      console.log('');
    }
    
    // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡è°ƒç”¨ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´
    if (i < 3) {
      console.log('â³ ç­‰å¾…10ç§’åç»§ç»­...\n');
      await new Promise(resolve => setTimeout(resolve, 10000));
    }
  }
}

testRateLimit().catch(console.error);